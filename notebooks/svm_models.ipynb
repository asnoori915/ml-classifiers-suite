{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lAEyJPNMB-0C",
    "outputId": "9c98c345-51e3-43fb-e5ea-03d58f2433bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-04-30 04:51:38--  https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data\n",
      "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
      "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified\n",
      "Saving to: ‘spambase.data.86’\n",
      "\n",
      "spambase.data.86        [  <=>               ] 686.47K  1.69MB/s    in 0.4s    \n",
      "\n",
      "2025-04-30 04:51:38 (1.69 MB/s) - ‘spambase.data.86’ saved [702942]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports\n",
    "\n",
    "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# from google.colab import files\n",
    "# uploaded = files.upload()\n",
    "english = [i.strip() for i in open('english.txt') if i.strip()]\n",
    "dutch = [i.strip() for i in open('dutch.txt') if i.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {
    "id": "_AYDBObVS__-"
   },
   "outputs": [],
   "source": [
    "# Cell 2: Perceptron\n",
    "\n",
    "# influenced by lecture 07, slide 27 pseudocode\n",
    "class Perceptron:\n",
    "    def __init__(self, max_iter=10):\n",
    "        self.max_iter = max_iter #iterations\n",
    "        self.w = None # weights\n",
    "        self.b = 0 # bias\n",
    "\n",
    "    def train(self, D, Y):\n",
    "        n, d = D.shape\n",
    "        self.w = np.zeros(d) # w ← 0 for all d\n",
    "        self.b = 0 # b ← 0\n",
    "\n",
    "        for iter in range(1, self.max_iter + 1):\n",
    "            for i in range(n): # for all (x, y) in D\n",
    "                x, y = D[i], Y[i]\n",
    "                a = np.dot(self.w, x) + self.b # activation\n",
    "                if y * a <= 0: # if y*a is <= 0 then update weights and bias\n",
    "                    self.w += y * x\n",
    "                    self.b += y\n",
    "\n",
    "    def predict(self, D): # returns trained model\n",
    "        return np.sign(np.dot(D, self.w) + self.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t7MEaXhoTDYp",
    "outputId": "837e8027-57da-4215-b6a4-9cf71be6c1e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set: (3680, 57)\n",
      "development set: (460, 57)\n",
      "test set: (461, 57)\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: spambase data\n",
    "\n",
    "data = np.loadtxt('spambase.data', delimiter=',')\n",
    "\n",
    "# split into features (X) and labels (y)\n",
    "X = data[:, :-1]\n",
    "y = np.where(data[:, -1] == 0, -1, 1)  # convert 0 to -1\n",
    "\n",
    "# 80% training set for D, and rest is dev and test (10% each)\n",
    "D_80, D_20, Y_80, Y_20 = train_test_split(X, y, test_size =0.2) # could add a state for consistent results\n",
    "\n",
    "# 10% dev, 10% test sets\n",
    "D_dev, D_test, Y_dev, Y_test = train_test_split(D_20, Y_20, test_size=0.5)\n",
    "\n",
    "# prints shapes\n",
    "print(\"training set:\", D_80.shape)\n",
    "print(\"development set:\", D_dev.shape)\n",
    "print(\"test set:\", D_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QRAi6jktTFj9",
    "outputId": "9e44db1d-3151-4222-b4d7-49bf7d4ab2c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron Accuracy: 83.51 %\n",
      "Perceptron Confusion Matrix:\n",
      " [[235  30]\n",
      " [ 46 150]]\n",
      "\n",
      "\n",
      "Logistic Regression Accuracy: 92.62 %\n",
      "Logistic Regression Confusion Matrix:\n",
      " [[255  10]\n",
      " [ 24 172]]\n",
      "\n",
      "\n",
      "Linear SVC Accuracy: 91.97 %\n",
      "Linear SVC Confusion Matrix:\n",
      " [[254  11]\n",
      " [ 26 170]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: training and results for spambase\n",
    "\n",
    "# train perceptron model\n",
    "p_spambase = Perceptron(max_iter=100)\n",
    "p_spambase.train(D_80, Y_80)\n",
    "# give the predictions from test set\n",
    "p_results = p_spambase.predict(D_test)\n",
    "print(\"Perceptron Accuracy:\", round(np.mean(p_results == Y_test) * 100, 2), \"%\")\n",
    "print(\"Perceptron Confusion Matrix:\\n\", confusion_matrix(Y_test, p_results))\n",
    "print(\"\\n\")\n",
    "\n",
    "# train logistic regression model\n",
    "LR_spambase = LogisticRegression(max_iter=1000)\n",
    "LR_spambase.fit(D_80, Y_80)\n",
    "# give the predictions from test set\n",
    "LR_results = LR_spambase.predict(D_test)\n",
    "# print results\n",
    "print(\"Logistic Regression Accuracy:\", round(np.mean(LR_results == Y_test) * 100, 2), \"%\")\n",
    "print(\"Logistic Regression Confusion Matrix:\\n\", confusion_matrix(Y_test, LR_results))\n",
    "print(\"\\n\")\n",
    "\n",
    "# train linear SVC model\n",
    "SVC_spambase = LinearSVC(max_iter=1000)\n",
    "SVC_spambase.fit(D_80, Y_80)\n",
    "# give the predictions from test set\n",
    "SVC_results = SVC_spambase.predict(D_test)\n",
    "# print results\n",
    "print(\"Linear SVC Accuracy:\", round(np.mean(SVC_results == Y_test) * 100, 2), \"%\")\n",
    "print(\"Linear SVC Confusion Matrix:\\n\", confusion_matrix(Y_test, SVC_results))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GfVnUaR7TJKN",
    "outputId": "0266010e-6296-44a6-8089-b6f084c04f7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set: (110, 12)\n",
      "development set: (14, 12)\n",
      "test set: (14, 12)\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: features for language\n",
    "\n",
    "# influenced by document suggestions and class\n",
    "def feats(s):\n",
    "    v = np.zeros(12)\n",
    "    s = s.lower()\n",
    "    v[0:3] = [s.count(x) for x in 'eao']\n",
    "    v[3:5] = [s.count(' '), len(s)]\n",
    "    v[5:10] = ['the ' in s, 'de ' in s or 'het ' in s, 'ij' in s or 'sch' in s,\n",
    "        s.endswith('ing'), s.endswith('lijk')]\n",
    "    v[10] = sum(s.count(x) for x in 'ëéèäöü')\n",
    "    v[11] = any(w in s for w in ['freedom', 'rights', 'vrijheid', 'rechten'])\n",
    "    return v.astype(int)\n",
    "\n",
    "# change them to vectors\n",
    "X_eng = np.array([feats(s) for s in english])\n",
    "X_dut = np.array([feats(s) for s in dutch])\n",
    "\n",
    "# make labels for english and dutch, 1, -1\n",
    "y_eng = np.ones(len(X_eng))\n",
    "y_dut = -np.ones(len(X_dut))\n",
    "X = np.vstack((X_eng, X_dut))\n",
    "y = np.concatenate((y_eng, y_dut))\n",
    "\n",
    "# 80% training set for D, and rest is dev and test (10% each)\n",
    "D_80, D_20, Y_80, Y_20 = train_test_split(X, y, test_size =0.2) # could add a state for consistent results\n",
    "\n",
    "# 10% dev, 10% test sets\n",
    "D_dev, D_test, Y_dev, Y_test = train_test_split(D_20, Y_20, test_size=0.5)\n",
    "\n",
    "# prints shapes\n",
    "print(\"training set:\", D_80.shape)\n",
    "print(\"development set:\", D_dev.shape)\n",
    "print(\"test set:\", D_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tD-hkopETLbC",
    "outputId": "25461d4f-676e-4e17-ad79-6eb208ef468a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron Language Accuracy: 92.86 %\n",
      "Perceptron Confusion Matrix:\n",
      " [[7 0]\n",
      " [1 6]]\n",
      "\n",
      "\n",
      "Logistic Regression Accuracy: 100.0 %\n",
      "Logistic Confusion Matrix:\n",
      " [[7 0]\n",
      " [0 7]]\n",
      "\n",
      "\n",
      "SVC Language Accuracy: 100.0 %\n",
      "SVC Confusion Matrix:\n",
      " [[7 0]\n",
      " [0 7]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: training and results of language files\n",
    "\n",
    "# train perceptron model\n",
    "p_language = Perceptron(max_iter=100)\n",
    "p_language.train(D_80, Y_80)\n",
    "p_results = p_language.predict(D_test)\n",
    "print(\"Perceptron Language Accuracy:\", round(np.mean(p_results == Y_test) * 100, 2), \"%\")\n",
    "print(\"Perceptron Confusion Matrix:\\n\", confusion_matrix(Y_test, p_results))\n",
    "print(\"\\n\")\n",
    "\n",
    "# train logistic regression model\n",
    "LR_language = LogisticRegression(max_iter=1000)\n",
    "LR_language.fit(D_80, Y_80)\n",
    "LR_results = LR_language.predict(D_test)\n",
    "print(\"Logistic Regression Accuracy:\", round(np.mean(LR_results == Y_test) * 100, 2), \"%\")\n",
    "print(\"Logistic Confusion Matrix:\\n\", confusion_matrix(Y_test, LR_results))\n",
    "print(\"\\n\")\n",
    "\n",
    "# train linear SVC model\n",
    "SVC_language = LinearSVC(max_iter=1000)\n",
    "SVC_language.fit(D_80, Y_80)\n",
    "SVC_results = SVC_language.predict(D_test)\n",
    "print(\"SVC Language Accuracy:\", round(np.mean(SVC_results == Y_test) * 100, 2), \"%\")\n",
    "print(\"SVC Confusion Matrix:\\n\", confusion_matrix(Y_test, SVC_results))\n",
    "print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PJL4AFyFTNC8",
    "outputId": "29494274-bd3b-4c5f-e970-307f8aa64f5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVELOPMENT SETS\n",
      "Perceptron Development Accuracy: 77.5 %\n",
      "Perceptron Confusion Matrix:\n",
      " [[18  2]\n",
      " [ 7 13]]\n",
      "LogReg Dev Accuracy: 87.5 %\n",
      "LogReg Confusion Matrix:\n",
      " [[17  3]\n",
      " [ 2 18]]\n",
      "SVC Dev Accuracy: 90.0 %\n",
      "SVC Confusion Matrix:\n",
      " [[18  2]\n",
      " [ 2 18]]\n",
      "\n",
      "TEST SETS\n",
      "Perceptron Test Accuracy: 80.0 %\n",
      "Perceptron Confusion Matrix:\n",
      " [[19  1]\n",
      " [ 7 13]]\n",
      "LogReg Test Accuracy: 90.0 %\n",
      "LogReg Confusion Matrix:\n",
      " [[18  2]\n",
      " [ 2 18]]\n",
      "SVC Test Accuracy: 92.5 %\n",
      "SVC Confusion Matrix:\n",
      " [[18  2]\n",
      " [ 1 19]]\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Evaluate models on new sentences\n",
    "\n",
    "# new sentences, 40 in each as I need 20 per set\n",
    "# from randomwordgenerator.com/sentence.php (and translate for dutch)\n",
    "new_english = [\n",
    "    \"Jerry liked to look at paintings while eating garlic ice cream.\",\n",
    "    \"I'm not a party animal, but I do like animal parties.\",\n",
    "    \"He shaved the peach to prove a point.\", \"He excelled at firing people nicely.\",\n",
    "    \"We will not allow you to bring your pet armadillo along.\",\n",
    "    \"I trust everything that's written in purple ink.\",\n",
    "    \"Joe made the sugar cookies; Susan decorated them.\",\n",
    "    \"There's an art to getting your way, and spitting olive pits across the table isn't it.\",\n",
    "    \"The best key lime pie is still up for debate.\",\n",
    "    \"Some bathing suits just shouldn’t be worn by some people.\",\n",
    "    \"This is the last random sentence I will be writing and I am going to stop mid-sent\",\n",
    "    \"The complicated school homework left the parents trying to help their kids quite confused.\",\n",
    "    \"I was starting to worry that my pet turtle could tell what I was thinking.\",\n",
    "    \"The pet shop stocks everything you need to keep your anaconda happy.\",\n",
    "    \"Thirty years later, she still thought it was okay to put the toilet paper roll under rather than over.\",\n",
    "    \"As she walked along the street and looked in the gutter, she realized facemasks had become the new cigarette butts.\",\n",
    "    \"It took him a while to realize that everything he decided not to change, he was actually choosing.\",\n",
    "    \"Being unacquainted with the chief raccoon was harming his prospects for promotion.\",\n",
    "    \"He would only survive if he kept the fire going and he could hear thunder in the distance.\",\n",
    "    \"The gloves protect my feet from excess work.\", \"He was sitting in a trash can with high street class.\",\n",
    "    \"Mothers spend months of their lives waiting on their children.\",\n",
    "    \"Her daily goal was to improve on yesterday.\", \"The near-death experience brought new ideas to light.\",\n",
    "    \"Henry couldn't decide if he was an auto mechanic or a priest.\",\n",
    "    \"Grape jelly was leaking out the hole in the roof.\",\n",
    "    \"He set out for a short walk, but now all he could see were mangroves and water were for miles.\",\n",
    "    \"He wondered why at 18 he was old enough to go to war, but not old enough to buy cigarettes.\",\n",
    "    \"He enjoys practicing his ballet in the bathroom.\",\n",
    "    \"There was no telling what thoughts would come from the machine.\",\n",
    "    \"They finished building the road they knew no one would ever use.\",\n",
    "    \"It would have been a better night if the guys next to us weren't in the splash zone.\",\n",
    "    \"There's a message for you if you look up.\", \"Iguanas were falling out of the trees.\",\n",
    "    \"They ran around the corner to find that they had traveled back in time.\",\n",
    "    \"There were a lot of paintings of monkeys waving bamboo sticks in the gallery.\",\n",
    "    \"He barked orders at his daughters but they just stared back with amusement.\",\n",
    "    \"8% of 25 is the same as 25% of 8 and one of them is much easier to do in your head.\",\n",
    "    \"The secret ingredient to his wonderful life was crime.\",\n",
    "    \"25 years later, she still regretted that specific moment.\"\n",
    "]\n",
    "\n",
    "\n",
    "new_dutch = [\n",
    "    \"Liefde is niet zoals pizza.\", \"Dit boek zal zeker je brein vloeibaar maken.\",\n",
    "    \"Ze stond erop dat het opruimen van je kast de sleutel was tot goed rijden.\",\n",
    "    \"Hij besloot al het zand op het strand te tellen als hobby.\",\n",
    "    \"Ze was verdrietig te horen dat vuurvliegjes met uitsterven bedreigd worden door kunstlicht, verlies van habitat en pesticiden.\",\n",
    "    \"Hij hield ervan zijn bananen in hotdogbroodjes te eten.\",\n",
    "    \"Patricia houdt van het geluid van nagels die stevig tegen het schoolbord worden gedrukt.\",\n",
    "    \"Waarheid in reclame en dinosaurussen met skateboards hebben veel gemeen.\",\n",
    "    \"Hij was het enige lid van de club die geen pruimenpudding lustte.\",\n",
    "    \"Hij vond regen fascinerend maar onaangenaam.\",\n",
    "    \"Terwijl hij aan het touw bungelde diep in de kloof...\",\n",
    "    \"De vleugels van de kolibrie vervaagden terwijl hij gretig de suikerwater uit de voeder dronk.\",\n",
    "    \"Het is niet moeilijk om een handstand te doen als je gewoon op je handen staat.\",\n",
    "    \"Je vindt niet vaak een zompige banaan op straat.\",\n",
    "    \"Kevin omarmde zijn vermogen om op de verkeerde plaats op het verkeerde moment te zijn.\",\n",
    "    \"Ze spreekt altijd met hem in een luide stem.\",\n",
    "    \"We zijn nog nooit in Azië geweest, noch hebben we Afrika bezocht.\",\n",
    "    \"Eindelijk...\",\n",
    "    \"Ze zag geen ironie in mij vragen te veranderen maar wilde dat ik haar accepteerde zoals ze is.\",\n",
    "    \"Erin creëerde per ongeluk een nieuw universum.\",\n",
    "    \"Het bord zei dat er wegwerkzaamheden waren, dus besloot hij te versnellen.\",\n",
    "    \"Het zou een betere nacht zijn geweest als de jongens naast ons niet in de spatzone zaten.\",\n",
    "    \"Combineer je designer cowboyhoed met duikuitrusting voor een gedenkwaardige gelegenheid.\",\n",
    "    \"Terwijl hij uit het raam keek, zag hij een clown voorbijlopen.\",\n",
    "    \"Mijn moeder probeert cool te zijn door te zeggen dat ze van dezelfde dingen houdt als ik.\",\n",
    "    \"Soms staar ik naar een deur of een muur en vraag me af wat deze realiteit is, waarom ik leef en waar dit allemaal over gaat.\",\n",
    "    \"De ironie van de situatie ging niet aan iemand in de kamer voorbij.\",\n",
    "    \"Ik woonde vroeger in de vijver van mijn buurman, maar het esthetische beviel me niet.\",\n",
    "    \"Eerlijk gezegd gaf ik niet veel om het eerste seizoen, dus heb ik het tweede niet gekeken.\",\n",
    "    \"Pat bestelde een spookpepertaart.\",\n",
    "    \"Ze hadden dringend een andere drummer nodig, aangezien de huidige alleen bongo's kon spelen.\",\n",
    "    \"Jason leefde zijn leven volgens het motto: 'Alles wat de moeite waard is om te doen, is de moeite waard om slecht te doen.'\",\n",
    "    \"Blauw klonk destijds te koud, maar het leek te werken voor gin.\",\n",
    "    \"Ik denk dat ik de rode auto zal kopen, of ik lease de blauwe.\",\n",
    "    \"Hoewel hij dacht dat de wereld plat was, zag hij de ironie niet in van de wens om de wereld rond te reizen.\",\n",
    "    \"Ze zeggen dat mensen belangrijke momenten in hun leven goed herinneren, toch herinnert niemand zich zijn eigen geboorte.\",\n",
    "    \"Ik ben blij je donatie aan te nemen; elk bedrag wordt zeer gewaardeerd.\",\n",
    "    \"Hij droeg het chirurgisch masker in het openbaar niet om een virus te vermijden, maar om mensen van zich weg te houden.\",\n",
    "    \"Hij had per ongeluk ingebroken op de server van zijn bedrijf.\",\n",
    "    \"Ondanks meerdere complicaties en haar bijna-doodervaring...\"\n",
    "]\n",
    "\n",
    "# development set, first 20 English + 20 Dutch\n",
    "devX = np.array([feats(s) for s in (new_english[:20] + new_dutch[:20])])\n",
    "devY = np.concatenate((np.ones(20), -np.ones(20)))\n",
    "\n",
    "# test set, next 20 English + 20 Dutch\n",
    "testX = np.array([feats(s) for s in (new_english[20:] + new_dutch[20:])])\n",
    "testY = np.concatenate((np.ones(20), -np.ones(20)))\n",
    "\n",
    "# Evaluate on dev set\n",
    "print(\"DEVELOPMENT SETS\")\n",
    "print(\"Perceptron Development Accuracy:\", round(np.mean(p_language.predict(devX) == devY) * 100, 2), \"%\")\n",
    "print(\"Perceptron Confusion Matrix:\\n\", confusion_matrix(devY, p_language.predict(devX)))\n",
    "print(\"LogReg Dev Accuracy:\", round(np.mean(LR_language.predict(devX) == devY) * 100, 2), \"%\")\n",
    "print(\"LogReg Confusion Matrix:\\n\", confusion_matrix(devY, LR_language.predict(devX)))\n",
    "print(\"SVC Dev Accuracy:\", round(np.mean(SVC_language.predict(devX) == devY) * 100, 2), \"%\")\n",
    "print(\"SVC Confusion Matrix:\\n\", confusion_matrix(devY, SVC_language.predict(devX)))\n",
    "\n",
    "# Evaluate on test set\n",
    "print(\"\\nTEST SETS\")\n",
    "print(\"Perceptron Test Accuracy:\", round(np.mean(p_language.predict(testX) == testY) * 100, 2), \"%\")\n",
    "print(\"Perceptron Confusion Matrix:\\n\", confusion_matrix(testY, p_language.predict(testX)))\n",
    "print(\"LogReg Test Accuracy:\", round(np.mean(LR_language.predict(testX) == testY) * 100, 2), \"%\")\n",
    "print(\"LogReg Confusion Matrix:\\n\", confusion_matrix(testY, LR_language.predict(testX)))\n",
    "print(\"SVC Test Accuracy:\", round(np.mean(SVC_language.predict(testX) == testY) * 100, 2), \"%\")\n",
    "print(\"SVC Confusion Matrix:\\n\", confusion_matrix(testY, SVC_language.predict(testX)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {
    "id": "WUfZORa_3hUt"
   },
   "outputs": [],
   "source": [
    "readme = \"\"\"\n",
    "Some Linear Classification Models\n",
    "By: Amir Noori\n",
    "\n",
    "Overview:\n",
    "This homework uses different classification models being a perceptron, logistic regression, and linear SVC to test their accuracies with two different databases. The databases being a spam email checklist and a language model that differentiates english and dutch with added features.\n",
    "\n",
    "Key Features:\n",
    "First there is a perceptron implementation.\n",
    "Then a spambase dataset is loaded and split with the differing classification models tested against each other.\n",
    "This process is repeated with the language model and once again with personally implemented data of sentences.\n",
    "This is done through training the data under the classification models and printing and tracking their results.\n",
    "\n",
    "Files:\n",
    "- `english.txt` / `dutch.txt`: Source text files\n",
    "- `spambase.data`: Public UCI dataset for spam classification\n",
    "\n",
    "To run this:\n",
    "1. Open the Colab notebook.\n",
    "2. Run each cell from top to bottom (or all at once using the Runtime --> Run All shortcut).\n",
    "3. Ensure the files are uploaded properly and are in the same filepaths if running locally.\n",
    "  - If there is an error there are commented lines in cell 1 that can be uncommented and run to upload the files and fix the issue.\n",
    "4. View resulting model accuracy and confusion matrices for both tasks.\n",
    "\n",
    "\"\"\"\n",
    "with open(\"README.txt\", \"w\") as f:\n",
    "    f.write(readme)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
